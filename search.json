[
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "Pierre-Yves de Müllenheim",
    "section": "",
    "text": "How to make a figure with several panels that include plots that are initially invisible? The case of the {corrplot} package\n\n\n\n\n\n\nR\n\n\nData visualization\n\n\nCorrelation\n\n\n\nMulti-panel figure using plots from {corrplot}\n\n\n\n\n\nNov 15, 2022\n\n\nPierre-Yves de Müllenheim\n\n\n\n\n\n\n\n\n\n\n\n\nActilife software procedures to get vector magnitude counts: are the computations exactly the same?\n\n\n\n\n\n\nactigraph\n\n\nactilife\n\n\ncounts\n\n\nvector magnitude\n\n\n\nExploring how vector magnitude is computed by Actilife software\n\n\n\n\n\nJul 1, 2022\n\n\nPierre-Yves de Müllenheim\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/actigraph-vm-counts/index.html",
    "href": "posts/actigraph-vm-counts/index.html",
    "title": "Actilife software procedures to get vector magnitude counts: are the computations exactly the same?",
    "section": "",
    "text": "Introduction\nWhen we measure movement using an ActiGraph accelerometer, we can access two kinds of signals (with GT1M devices and more recent generations of devices): the raw acceleration signal, now expressed in G force units; and the activity counts signal, that describes the amount of body acceleration performed over defined epochs (e.g., 1-s epochs) (Chen & Bassett, 2005; John & Freedson, 2012).\nActivity counts have been commonly used in physical activity studies to estimate time spent in different movement intensities or total amount of movement performed during the day (Bassett et al., 2015). In general, the counts of interest are related to the vertical axis or the vector magnitude (VM), VM being the norm of the movement vector defined as \\(VM = \\sqrt{x^2 + y^2 + z^2}\\), with \\(x\\), \\(y\\), and \\(z\\) the counts related to each accelerometer axis for each epoch, respectively.\nWhen using an ActiGraph accelerometer, VM can be obtained when exporting data from Actilife software to a spreadseet, as for example when exporting the whole dataset to DataTable format, or when exporting the detected wear time epochs (after wear time analysis) to a simple .csv file. Other software programs allow getting VM data, such as R software along with the PhysicalActivity R package (Choi et al., 2021). The PhysicalActivity package is well known for its implementation of a nonwear time detection algorithm (Choi et al., 2012), but this package also contains a specific function (the readActigraph() function) to read .agd files and then to compute VM.\nAn interesting thing with R packages is that code is open, allowing to know exactly what computations are performed when a function returns a result. For example, the readActigraph() function from the PhysicalActivity package actually uses a ceiling() function on the computed VM data. This means that from each inital VM value computed with the function, the function returns at the end the smallest integer that is not lower than the considered value (e.g., for an initial VM value of 4.33, the function will actually return the value 5). Thus, the VM data that are finally obtained from the readActigraph() function are a little transformed. When using Actilife software, it is however more complicated to know what computations are exactly performed when getting VM values. At the end of a personal analysis, I was surprised to see that VM values could be slightly different depending on the procedure used to export data to spreadsheets from Actilife software. Thus, I have performed some analyses to understand how VM values provided by Actilife software are exactly computed and to know to what extent Actilife computation procedures may differ from each other and from other software ressources, specifically the readActigraph() function from the PhysicalActivity R package.\n\n\nMethods\nData used in this post were initially obtained following a personnal mesurement of physical behaviour performed using an ActiGraph wGT3X-BT device (sampling rate: 90 Hz) worn at the hip during two weeks. Once the measurement completed, data were downloaded from the device using Actilife software v6.13.4 and two .agd files were created by accumulating activity counts using either 60-s epochs or 1-s epochs, and using the normal filter for both files. Finally, I have produced four different datasets for both 60-s epochs and 1-epochs:\n\nA dataset containing VM data computed in R using the VM formula on the .agd file data and a rounding function (2 digits) on the VM values (this procedure is called basic thereafter).\nA dataset containing VM data computed in R using the readActigraph() function from the PhysicalActivity R package on the .agd file data (this procedure is called choi thereafter).\nA dataset containing VM data computed by Actilife software when exporting data to DataTable format (this procedure is called acti_datatable thereafter).\nA dataset containing VM data computed by Actilife software when exporting data after wear time analysis (this procedure is called acti_weartime thereafter).\n\nThen, for all datasets containing 60-s epochs and 1-epochs, I have applied in R the wearingMarking() function from the PhysicalActivity R package to finally keep only the wear time epochs from Day 2. This allowed me to make all the datasets comparable for a given epoch length and to reduce their size for faster analysis. The 60-s epoch datasets had 1055 observations each, while the 1-s epoch datasets had 63300 observations each.\nTo explore potential differences in VM values depending on the software procedure that was used, I have performed the followings: scatter plots for bivariate analyses using all the VM values; bar plots to look at the differences in total VM counts; table view to look at a short sample of VM values obtained from each software procedure.\nThe R code written to produce data and results can be viewed when clicking on the Code buttons in the remaining part of the post.\n\n\nCode\n# Packages & functions ---------------------------------------------------------\n## Packages\nlibrary(actigraph.sleepr)\nlibrary(PhysicalActivity)\nlibrary(dplyr)\nlibrary(readr)\nlibrary(tidyr)\nlibrary(lubridate)\nlibrary(ggplot2)\nlibrary(ggforce)\nlibrary(patchwork)\nlibrary(forcats)\nlibrary(colorblindr)\nlibrary(reactable)\nlibrary(SimDesign)\n\n## Below a function to correctly read accelerometer data exported to 'DataTable'\n## format from Actilife software. This function solves the problem that data are\n## exported from Actilife with quotes for the 'DataTable' format (the function \n## removes the quotes).\nread_datatable &lt;- function(file) {\n  my_data &lt;- read_csv(file, skip = 10, quote = \"\")\n  my_data2 &lt;- lapply(my_data, function(x) { gsub(\",\", \".\", x) }) %&gt;% as.data.frame()\n  my_data3 &lt;- lapply(my_data2, function(x) { gsub(\"\\\"\", \"\", x) }) %&gt;% \n    as.data.frame() %&gt;% \n    mutate(Vector.Magnitude = as.numeric(Vector.Magnitude))\n\n  return(my_data3)\n}\n\n# Get data\n## Datasets with VM obtained using the basic formula of VM (values are rounded \n## with 2 digits)\nbasic_60s &lt;- \n  quiet(\n    actigraph.sleepr::read_agd(\"data_60sec.agd\") %&gt;%\n    rename(TimeStamp = timestamp) %&gt;%\n    as.data.frame() %&gt;%\n    mutate(vm = round(sqrt(axis1^2 + axis2^2 + axis3^2), 2)) %&gt;% \n    wearingMarking(cts = \"vm\", frame = 90, streamFrame = 30, allowanceFrame = 2) %&gt;% \n    filter(days == \"2\" & wearing == \"w\")\n  )\n\nbasic_1s &lt;-\n quiet(\n   actigraph.sleepr::read_agd(\"data_1sec.agd\") %&gt;%\n   rename(TimeStamp = timestamp) %&gt;%\n   as.data.frame() %&gt;%\n   mutate(vm = round(sqrt(axis1^2 + axis2^2 + axis3^2), 2)) %&gt;% \n   wearingMarking(cts = \"vm\", frame = 90, streamFrame = 30, allowanceFrame = 2) %&gt;% \n   filter(days == \"2\" & wearing == \"w\")\n )\n\n## Datasets with VM obtained using the readActigraph() function from the \n## PhysicalActivity R package\nchoi_60s &lt;-\n  quiet(\n    readActigraph(\"data_60sec.agd\") %&gt;% \n    wearingMarking(cts = \"vm\", frame = 90, streamFrame = 30, allowanceFrame = 2) %&gt;% \n    filter(days == \"2\" & wearing == \"w\")\n   )\n\nchoi_1s &lt;- \n  quiet(\n    readActigraph(\"data_1sec.agd\") %&gt;% \n    wearingMarking(cts = \"vm\", frame = 90, streamFrame = 30, allowanceFrame = 2) %&gt;% \n    filter(days == \"2\" & wearing == \"w\")\n   )\n\n## Datasets with VM obtained after exporting data from Actilife to 'DataTable' \n## format\ndataTable_60s &lt;- \n quiet(\n    read_datatable(\"data_DataTable_60sec.csv\") %&gt;%\n    unite(TimeStamp, Date, Time, sep = \" \") %&gt;%\n    mutate(TimeStamp = lubridate::dmy_hms(TimeStamp),\n           TimeStamp = as.character(TimeStamp)) %&gt;%\n    wearingMarking(cts = \"Vector.Magnitude\", frame = 90, streamFrame = 30, allowanceFrame = 2) %&gt;% \n    filter(days == \"2\" & wearing == \"w\")\n   )\n\ndataTable_1s &lt;- \n quiet(\n   read_datatable(\"data_DataTable_1sec.csv\") %&gt;%\n   unite(TimeStamp, Date, Time, sep = \" \") %&gt;%\n   mutate(TimeStamp = lubridate::dmy_hms(TimeStamp),\n          TimeStamp = as.character(TimeStamp)) %&gt;%\n   wearingMarking(cts = \"Vector.Magnitude\", frame = 90, streamFrame = 30, allowanceFrame = 2) %&gt;% \n   filter(days == \"2\" & wearing == \"w\")\n   )\n\n## Datasets with VM obtained after exporting data from Actilife following wear \n## time analysis\nWearTimeAnalysis_60s &lt;-\n quiet(\n   read_csv(\"data_WearTimeAnalysis_60sec.csv\", skip = 1) %&gt;%\n   unite(TimeStamp, date, epoch, sep = \" \") %&gt;%\n   mutate(TimeStamp = lubridate::dmy_hms(TimeStamp),\n          TimeStamp = as.character(TimeStamp)) %&gt;%\n   as.data.frame() %&gt;%\n   wearingMarking(cts = \"vm\", frame = 90, streamFrame = 30, allowanceFrame = 2) %&gt;% \n   filter(days == \"2\" & wearing == \"w\")\n   )\n\nWearTimeAnalysis_1s &lt;- \n quiet(\n   read_csv(\"data_WearTimeAnalysis_1sec.csv\", skip = 1) %&gt;%\n   unite(TimeStamp, date, epoch, sep = \" \") %&gt;%\n   mutate(TimeStamp = lubridate::dmy_hms(TimeStamp),\n          TimeStamp = as.character(TimeStamp)) %&gt;%\n   as.data.frame() %&gt;%\n   wearingMarking(cts = \"vm\", frame = 90, streamFrame = 30, allowanceFrame = 2) %&gt;% \n   filter(days == \"2\" & wearing == \"w\")\n   )\n\n\n\n\nResults & Discussion\nFigure 1 shows the bivariate relationships between the VM values obtained from the different software procedures. The graphics placed in the diagonale of the figure from the top-left corner to the bottom-right corner show the distributions of the counts values for the corresponding software procedures without using the y-scale of the figure. Each procedure seems perfectly correlated with each other.\n\n\nCode\n# Scatter plots analysis\n## Gather all VM variables into a single dataset\nall_60s &lt;-\n  data.frame(\n    basic = basic_60s$vm,\n    choi = choi_60s$vm,\n    acti_datatable = dataTable_60s$Vector.Magnitude,\n    acti_weartime = WearTimeAnalysis_60s$vm\n  )\n\nall_1s &lt;-\n  data.frame(\n    basic = basic_1s$vm,\n    choi = choi_1s$vm,\n    acti_datatable = dataTable_1s$Vector.Magnitude,\n    acti_weartime = WearTimeAnalysis_1s$vm\n  )\n\n## Create scatter plots\ng1 &lt;- \n  ggplot(all_60s, aes(x = .panel_x, y = .panel_y)) + \n  geom_point(alpha = 0.4, shape = 16, size = 2) + \n  geom_smooth(method = \"lm\", se = FALSE, size = 1) + \n  geom_autodensity() +\n  geom_rect(aes(\n    xmin = -Inf, \n    xmax = Inf, \n    ymin = -Inf, \n    ymax = Inf), \n    fill = \"grey90\"\n    ) +\n  facet_matrix(\n    vars(everything()), \n    layer.lower = c(1,2), \n    layer.diag = 3, \n    layer.upper = 4, \n    grid.y.diag = FALSE) +\n  labs(title = \"60-s epoch VM counts\")\n\ng2 &lt;- \n  ggplot(all_1s, aes(x = .panel_x, y = .panel_y)) + \n  geom_point(alpha = 0.4, shape = 16, size = 2) + \n  geom_smooth(method = \"lm\", se = FALSE, size = 1) + \n  geom_autodensity() +\n  geom_rect(aes(\n    xmin = -Inf, \n    xmax = Inf, \n    ymin = -Inf, \n    ymax = Inf), \n    fill = \"grey90\"\n    ) +\n  facet_matrix(\n    vars(everything()), \n    layer.lower = c(1,2), \n    layer.diag = 3, \n    layer.upper = 4, \n    grid.y.diag = FALSE) +\n  labs(title = \"\\n1-s epoch VM counts\")\n\n\n\n\n\n\n\n\n\n\nFigure 1: Relationships between the VM values obtained from the different software procedures\n\n\n\n\n\nFigure 2 (top panel) shows that total VM counts are different between the tested software procedures. Indeed, total VM counts ranged from 415,312 counts (acti_weartime procedure) to 415,600 counts (choi procedure) for the 60-s epoch datasets, and from 461,795 counts (acti_weartime procedure) to 466,017 counts (choi procedure) for the 1-s epoch datasets. Figure 2 (bottom panel) also shows that the differences between the procedures for total VM counts were higher when using 1-s epochs in comparison with the use of 60-s epochs. This last result may be put into relation with the fact that there were more observations when using 1-epochs compared to 60-s epochs, thus letting more room for total differences. Of note, the basic procedure and the acti_datatable procedure led to the same results, suggesting that Actilife software uses the VM formula and then a rounding procedure (2 digits) to provide VM values when exporting to DataTable-format spreadsheets.\n\n\nCode\n# Bar plots analysis\n## Build datasets with total VM counts per day and differences between procedures\n## with the 'acti_weartime' procedure as reference\nsum_60s &lt;-\n  all_60s %&gt;%\n  pivot_longer(cols= c(basic:acti_weartime), names_to = \"factor\", values_to = \"vm\") %&gt;%\n  group_by(factor) %&gt;%\n  summarise(total_counts = sum(vm)) %&gt;%\n  mutate(\n    epoch = \"60-s epoch\",\n    diff = total_counts - min(.$total_counts)\n  )\n\nsum_1s &lt;-\n  all_1s %&gt;%\n  pivot_longer(cols= c(basic:acti_weartime), names_to = \"factor\", values_to = \"vm\") %&gt;%\n  group_by(factor) %&gt;%\n  summarise(total_counts = sum(vm)) %&gt;%\n  mutate(\n    epoch = \"1-s epoch\",\n    diff = total_counts - min(.$total_counts)\n  )\n\nall_data &lt;-\n  bind_rows(sum_60s, sum_1s) %&gt;%\n  mutate(epoch = fct_relevel(as.factor(epoch), \"60-s epoch\", \"1-s epoch\"))\n\n## Create bar plots\ng3 &lt;- \n  ggplot(data = all_data, aes(x = fct_reorder(factor, total_counts), y = total_counts, fill = factor)) +\n  geom_bar(stat  = \"identity\") +\n  geom_text(aes(label = format(round(total_counts, 2), big.mark = \",\", scientific = FALSE)), nudge_y = 20000, size = 7) +\n  labs(\n    title = \"Total VM counts\",\n    fill = \"Computation method\",\n    y = \"Total VM counts\"\n  ) +\n  facet_wrap(.~ epoch) +\n  scale_fill_OkabeIto() +\n  theme(\n    axis.title = element_blank(),\n    axis.text.y = element_blank(),\n    axis.ticks.y = element_blank(),\n    legend.title = element_text(face = \"bold\")\n  )\n\ng4 &lt;-\n  ggplot(data = all_data, aes(x = fct_reorder(factor, diff), y = diff, fill = factor)) +\n  geom_bar(stat  = \"identity\") +\n  geom_text(aes(label = ifelse(factor == \"acti_weartime\", \"Reference\",\n                               round(diff, 2))), nudge_y = 150, size = 7) +\n  labs(\n    title = \"\\nDifferences in total VM counts from the acti_weartime procedure\",\n    fill = \"Computation method\",\n    y = \"Diff. VM counts\"\n  ) +\n  facet_wrap(.~ epoch) +\n  scale_fill_OkabeIto() +\n  theme(\n    axis.title = element_blank(),\n    axis.text.y = element_blank(),\n    axis.ticks.y = element_blank(),\n    legend.title = element_text(face = \"bold\")\n  ) \n\n\n\n\n\n\n\n\n\n\nFigure 2: Comparison of total VM counts between the different software procedures\n\n\n\n\n\nNow, it remains to investigate what computations may be related to the acti_weartime procedure and why there were such differences between the various computation procedures. To do this, let’s take a look at a sample of VM values from the different datasets with 60-s epochs (Figure 3).\n\n\nCode\ntable &lt;- (all_60s %&gt;% select(acti_weartime, acti_datatable, basic, choi)) [21:30, ]\norange_pal &lt;- function(x) rgb(colorRamp(c(\"#ffe4cc\", \"#ff9500\"))(x), maxColorValue = 255)\nreactable(table,\n      defaultColDef = colDef(align = \"center\", width = 180),\n      columns = list(\n        acti_weartime = colDef(style = function() list(background = \"#56B4E9\")),\n        acti_datatable = colDef(style = function() list(background = \"#E69F00\")),\n        basic = colDef(style = function() list(background = \"#009E73\")),\n        choi = colDef(style = function() list(background = \"#F0E442\"))\n       )\n)\n\n\n\n\n\n\n\n\nFigure 3: Sample of VM values from the 60-s epoch datasets obtained with the different software procedures\n\n\n\n\nFrom Figure 3, we can guess that Actilife software actually uses two different rounding methods when computing VM values with the acti_weartime procedure, these methods depending on the decimal part of the initial VM value. Assuming the values from the basic procedure can be used as reference to provide an idea of what should be initial VM values, we can describe these two methods as follows:\n\nMethod 1: When the decimal part of the initial VM value is &gt;= 0.5, the value of the integer directly above the initial value of VM is returned;\nMethod 2: When the decimal part of the initial VM value is &lt; 0.5, the value of the integer directly below the initial value of VM is returned.\n\nThus, we can understand why the choi procedure provides total VM counts that are clearly larger than those from the other procedures: while the basic and acti_datatable procedures will keep the decimal part of the initial VM values, the choi procedure will always return values larger than the initial values of VM if the decimal part is above 0, while the acti_weartime procedure will return either larger VM values or smaller VM values than the initial VM values depending on if the decimal part of the initial VM value is &gt;=0.5 or not, respectively.\n\n\nConclusion\nIn this post, we have seen that two procedures related to Actilife software to export VM data provide different values from each other and also differ from the readActigraph() function retrieved from the PhysicalActivity R package:\n\nThe acti_datatable procedure (DataTable format from Actilife software) only rounds (2 digits) the VM values obtained using the basic VM formula.\nThe acti_weartime procedure (data obtained after wear time analysis from Actilife software) returns the integer directly above the initial VM value when the decimal part of the initial VM value is &gt;= 0.5, otherwise it returns the integer directly below the initial VM value.\nThe choi procedure always returns the integer directly above the initial VM value when the decimal part of the initial VM value is &gt;0.\n\nWhile the two tested Actilife procedures provide quite similar total VM counts values, the readActigraph() function seems to provide clearly larger total VM counts values at the end of the day. However, one could still consider such a difference as trivial. Indeed, the absolute difference of 4222 counts between the choi procedure and the acti_weartime procedure, when using 1-s epochs, represents only 0.9% of the total VM counts related to the acti_weartime procedure over the whole day. We could have the same perspective on the differences observed between total VM counts from the 60-s epoch datasets and 1-s epoch datasets. These differences are clear, but could be considered as trivial compared to the expected absolute value of total VM counts over a whole day. That’s being said, if there was no rationale to create such different procedures, it could be good thing to make all of these procedures similar from a computational point of view, for example by keeping the simple rounding procedure of the VM values to not distort the inital data.\n\n\n\n\n\n\n\n\nReferences\n\nBassett, D. R., Troiano, R. P., Mcclain, J. J., & Wolff, D. L. (2015). Accelerometer-based physical activity: Total volume per day and standardized measures. Med Sci Sports Exerc, 47(4), 833–838. https://doi.org/10.1249/MSS.0000000000000468\n\n\nChen, K. Y., & Bassett, D. R. (2005). The technology of accelerometry-based activity monitors: Current and future. Med Sci Sports Exerc, 37(11), S490–S500. https://doi.org/10.1249/01.mss.0000185571.49104.82\n\n\nChoi, L., Beck, C., Liu, Z., Moore, R., Matthews, C. E., & Buchowski, M. S. (2021). PhysicalActivity: Process accelerometer data for physical activity measurement (Version 0.2-4). https://CRAN.R-project.org/package=PhysicalActivity\n\n\nChoi, L., Ward, S. C., Schnelle, J. F., & Buchowski, M. S. (2012). Assessment of wear/nonwear time classification algorithms for triaxial accelerometer. Med Sci Sports Exerc, 44(10), 2009–2016. https://doi.org/10.1249/MSS.0b013e318258cb36\n\n\nJohn, D., & Freedson, P. (2012). ActiGraph and Actical physical activity monitors: A peek under the hood. Med Sci Sports Exerc, 44, S86–S89. https://doi.org/10.1249/MSS.0b013e3182399f5e"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "I’m Pierre-Yves de Müllenheim, an assistant professor at the Institute of Physical Education and Sport Sciences in Angers, France. My research focuses on developing and implementing wearable device-based methods to measure physical activity and walking capacity, especially in patients with chronic diseases and mobility impairments. Additionally, I am interested in developing and utilizing open-source algorithms and web applications to analyze data from wearable devices, with a particular emphasis on using the R programming language."
  },
  {
    "objectID": "in_posts.html",
    "href": "in_posts.html",
    "title": "LinkedIn",
    "section": "",
    "text": "06/04/2025 | Le bruit, un stress des grandes villes…  LINK \n\n\n\n\n\n31/12/2024 | 2025 approche ! Voici donc ci-dessous quelques idées de bonnes résolutions à envisager pour nos activités de recherche si ce n’est pas encore fait…  LINK \n\n\n\n\n\n18/11/2024 | Nouvel article : Change in exercise capacity, physical activity and motivation for physical activity at 12 months after a cardiac rehabilitation program in coronary heart disease patients: a prospective, monocentric and observational study  LINK \n\n\n\n\n\n31/12/2023 | My most appreciated readings about open and reproducible research for the year 2023  LINK \n\n\n\n\n\n11/08/2023 | Et si on incluait l’évaluation de l’activité physique (AP) dans le dossier médical électronique lors de consultations en soins primaires ? (idées reposant sur le rapport de l’AHA - 2018)  LINK \n\n\n\n\n\n06/08/2023 | De l’importance d’étudier les effets sociétaux des interventions promouvant l’activité physique (résumé d’un éditorial publié dans JPAH - 2023)  LINK \n\n\n\n\n\n05/08/2023 | Stratégies d’intervention liées à l’environnement construit pour augmenter le niveau d’activité physique (résumé du rapport de l’AHA - 2020)  LINK \n\n\n\n\n\n31/07/2023 | Effet des évènements de vie sur le niveau d’activité physique (résumé du rapport de l’AHA - 2021)  LINK \n\n\n\n\n\n23/07/2023 | Chaque minute compte (résumé d’un éditorial paru dans JAMA - 2023)  LINK"
  },
  {
    "objectID": "posts/corrplot-multiplots/index.html",
    "href": "posts/corrplot-multiplots/index.html",
    "title": "How to make a figure with several panels that include plots that are initially invisible? The case of the {corrplot} package",
    "section": "",
    "text": "The problem\nSome days ago, I was contacted by a student who wanted to visualize several sets of correlation values on the same figure. Making a multi-panel figure using correlation plots produced from the {corrplot} package seemed an interesting option. However, I met several unexpected problems to get the desired result. In this post, I share the solutions I have found to finally get a good result after some time spent on the web.\nFirst, let’s load the packages required for our analyses:\n\nlibrary(palmerpenguins)\nlibrary(dplyr)\nlibrary(corrplot)\nlibrary(ggplotify)\nlibrary(cowplot)\nlibrary(ragg)\n\nSecond, let’s get some data, here from the {palmerpenguins} package that provides physical characteristics of three species of penguins:\n\ndata(\"penguins\")\n\nThird, let’s compute correlation matrices putting into relation the physical characteristics for each of the three species of penguins:\n\n# Correlation matrix for 'Adelie' specie\nmat_adelie &lt;- \n  penguins %&gt;% \n  filter(species == \"Adelie\") %&gt;%\n  select(bill_length_mm: body_mass_g) %&gt;%\n  cor(use = \"pairwise.complete.obs\")\n  \n# Correlation matrix for 'Gentoo' specie\nmat_gentoo &lt;- \n  penguins %&gt;% \n  filter(species == \"Gentoo\") %&gt;%\n  select(bill_length_mm: body_mass_g) %&gt;%\n  cor(use = \"pairwise.complete.obs\")\n  \n# Correlation matrix for 'Chinstrap' specie\nmat_chinstrap &lt;- \n  penguins %&gt;% \n  filter(species == \"Chinstrap\") %&gt;%\n  select(bill_length_mm: body_mass_g) %&gt;%\n  cor(use = \"pairwise.complete.obs\")\n\nThen, I thought I could simply assign the output of the corrplot() function from the {corrplot} package (i.e., the function that generates the correlation plot) to a name, say p, which could have allow me to use p when building the targeted multi-panel figure. Here the example for the correlation matrix related to the Adelie specie:\n\np &lt;-\n    corrplot(\n      mat_adelie, \n      method =\"color\", \n      type =\"lower\", \n      tl.col =\"black\",\n      addCoef.col = \"black\",\n      mar = c(0,0,0,0)\n  )\n\n\n\n\n\n\n\n\nUnfortunately, this did not work. p did not return a plot, but the list of the information that were used when generating the plot:\n\np\n\n$corr\n                  bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\nbill_length_mm         1.0000000     0.3914917         0.3257847   0.5488658\nbill_depth_mm          0.3914917     1.0000000         0.3076202   0.5761382\nflipper_length_mm      0.3257847     0.3076202         1.0000000   0.4682017\nbody_mass_g            0.5488658     0.5761382         0.4682017   1.0000000\n\n$corrPos\n               xName             yName x y      corr\n1     bill_length_mm    bill_length_mm 1 4 1.0000000\n2     bill_length_mm     bill_depth_mm 1 3 0.3914917\n3     bill_length_mm flipper_length_mm 1 2 0.3257847\n4     bill_length_mm       body_mass_g 1 1 0.5488658\n5      bill_depth_mm     bill_depth_mm 2 3 1.0000000\n6      bill_depth_mm flipper_length_mm 2 2 0.3076202\n7      bill_depth_mm       body_mass_g 2 1 0.5761382\n8  flipper_length_mm flipper_length_mm 3 2 1.0000000\n9  flipper_length_mm       body_mass_g 3 1 0.4682017\n10       body_mass_g       body_mass_g 4 1 1.0000000\n\n$arg\n$arg$type\n[1] \"lower\"\n\n\nThe reason is that the plot is made “invisible” when it is provided by the corrplot() function, making it impossible to directly catch.\n\n\nThe solutions\nAt first glance, I could have decided to abandon the idea of using several graphic objects to be combined into a multi-panel figure, and then I could have stopped after the implementation of the following solution proposed on Stack Overflow:\n\npar(mfrow = c(1, 3))\ncorrplot(\n  mat_adelie, \n  method = \"color\", \n  type = \"lower\", \n  tl.col = \"black\",\n  addCoef.col = \"black\",\n  mar = c(0,0,0,0),\n  tl.cex = 2.5,\n  number.cex = 2.5\n  )\ncorrplot(\n  mat_gentoo, \n  method = \"color\", \n  type = \"lower\", \n  tl.col = \"black\",\n  addCoef.col = \"black\",\n  mar = c(0,0,0,0),\n  tl.cex = 2.5,\n  number.cex = 2.5\n  )\ncorrplot(\n  mat_chinstrap, \n  method = \"color\", \n  type = \"lower\", \n  tl.col = \"black\",\n  addCoef.col = \"black\",\n  mar = c(0,0,0,0),\n  tl.cex = 2.5,\n  number.cex = 2.5\n  )\n\n\n\n\n\n\n\npar(mfrow = c(1, 1)) # To clear layout\n\nHowever, one could want to be able to catch the plot from the corrplot() function and to bind it to a name so that it can be used elsewhere in a more complex figure. What I have learnt is that it remains possible to do it by using a customized function that would return the last plot shown in the graphic device, as proposed on Stack Overflow:\n\nget_corr_plot &lt;- function(matrix) {\n  corrplot(\n    matrix,\n    method = \"color\", \n    type = \"lower\", \n    tl.col = \"black\",\n    addCoef.col = \"black\",\n    mar = c(0,0,0,0),\n    tl.cex = 2,\n    number.cex = 2\n    )\n\n  p &lt;- recordPlot()\n\n  return(p)\n}\n\nIn the code above, you will notice that the last plot is recorded thanks to the recordPlot() function from the {grDevices} package. The new problem is now that the function returns an object of class recordedplot, which is not yet really interesting to make complex figures as one could want to do with the {cowplot} package for example because the class recordedplot may not be accepted by the package functions. A solution is then to convert the recordedplot object to a grob object using the function as.grob() from the {ggplotify} package, as follows:\n\ngrob_adelie &lt;- as.grob(~get_corr_plot(matrix = mat_adelie))\ngrob_gentoo &lt;- as.grob(~get_corr_plot(matrix = mat_gentoo))\ngrob_chinstrap &lt;- as.grob(~get_corr_plot(matrix = mat_chinstrap))\n\nWe can finally use the plot_grid() function from the {cowplot} package to draw our final figure:\n\nfig &lt;- plot_grid(grob_adelie, grob_gentoo, grob_chinstrap, nrow = 1, labels=LETTERS[1:3], label_size = 25)\nfig\n\n\n\n\n\n\n\n\n\n\nThe final touch\nThe graphic device may not always provide an approriate view of the figure. To have more control on this when we want to export the figure, we can use the {ragg} package as follows (maybe several trials and errors when manipulating the width, height, and scaling arguments will be needed to get satisfactory results; for more information, please see the Thomas Lin Pedersen’s post):\n\nagg_png(\n  \"posts/corrplot-multiplots/index_files/figure-html/fig.png\", \n  width = 21, \n  height = 7, \n  units = \"cm\",\n  res = 300,\n  scaling = 0.4\n)\nfig\ndev.off()\n\nEt voilà, we are done!\n\n\nSession info\n\n\nR version 4.2.1 (2022-06-23 ucrt)\nPlatform: x86_64-w64-mingw32/x64 (64-bit)\nRunning under: Windows 10 x64 (build 19043)\n\nMatrix products: default\n\nlocale:\n[1] LC_COLLATE=French_France.utf8  LC_CTYPE=French_France.utf8   \n[3] LC_MONETARY=French_France.utf8 LC_NUMERIC=C                  \n[5] LC_TIME=French_France.utf8    \n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] ragg_1.2.3           ggplotify_0.1.0      cowplot_1.1.1       \n[4] corrplot_0.92        dplyr_1.0.10         palmerpenguins_0.1.1\n\nloaded via a namespace (and not attached):\n [1] pillar_1.8.1       compiler_4.2.1     yulab.utils_0.0.5  tools_4.2.1       \n [5] digest_0.6.29      jsonlite_1.8.3     evaluate_0.18      lifecycle_1.0.3   \n [9] tibble_3.1.8       gtable_0.3.1       pkgconfig_2.0.3    rlang_1.0.6       \n[13] cli_3.4.1          DBI_1.1.3          rstudioapi_0.14    yaml_2.3.6        \n[17] xfun_0.34          fastmap_1.1.0      stringr_1.4.1      knitr_1.40        \n[21] systemfonts_1.0.4  gridGraphics_0.5-1 generics_0.1.3     vctrs_0.5.0       \n[25] htmlwidgets_1.5.4  grid_4.2.1         tidyselect_1.2.0   glue_1.6.2        \n[29] R6_2.5.1           textshaping_0.3.6  fansi_1.0.3        rmarkdown_2.17    \n[33] ggplot2_3.4.0      magrittr_2.0.3     scales_1.2.1       htmltools_0.5.3   \n[37] assertthat_0.2.1   colorspace_2.0-3   utf8_1.2.2         stringi_1.7.8     \n[41] munsell_0.5.0"
  }
]